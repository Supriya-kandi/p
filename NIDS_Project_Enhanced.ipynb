{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a2b02d",
   "metadata": {},
   "source": [
    "# AI-Powered Network Intrusion Detection System (NIDS) using Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b95eff",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Step 1: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt\"\n",
    "test_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest+.txt\"\n",
    "\n",
    "# Define column names (from NSL-KDD documentation)\n",
    "col_names = [\n",
    "    \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\n",
    "    \"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\n",
    "    \"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\n",
    "    \"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\n",
    "    \"label\",\"difficulty_level\"\n",
    "]\n",
    "\n",
    "# Read the data\n",
    "train_df = pd.read_csv(train_url, names=col_names)\n",
    "test_df = pd.read_csv(test_url, names=col_names)\n",
    "\n",
    "# Drop difficulty_level\n",
    "train_df.drop(\"difficulty_level\", axis=1, inplace=True)\n",
    "test_df.drop(\"difficulty_level\", axis=1, inplace=True)\n",
    "\n",
    "# Show sample data\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772b548a",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Step 2: Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbff48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Copy to preserve originals\n",
    "df_train = train_df.copy()\n",
    "df_test = test_df.copy()\n",
    "\n",
    "# âœ… Binary classification: 0 for 'normal', 1 for all other attack labels\n",
    "df_train['label'] = df_train['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "df_test['label'] = df_test['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "# Split features and target\n",
    "X_train = df_train.drop('label', axis=1)\n",
    "y_train = df_train['label']\n",
    "X_test = df_test.drop('label', axis=1)\n",
    "y_test = df_test['label']\n",
    "\n",
    "# Categorical columns\n",
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "\n",
    "# OneHotEncoder to handle unseen categories\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply encoding\n",
    "X_train_encoded = column_transformer.fit_transform(X_train)\n",
    "X_test_encoded = column_transformer.transform(X_test)\n",
    "\n",
    "print(\"âœ… Preprocessing done. X_train shape:\", X_train_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c710d8a",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Step 3: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8555019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = clf.predict(X_test_encoded)\n",
    "\n",
    "# Evaluation\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed2e76",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Step 4: Save and Use the Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7638b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "# Save model and preprocessor\n",
    "joblib.dump(clf, 'nids_rf_model.pkl')\n",
    "joblib.dump(column_transformer, 'nids_preprocessor.pkl')\n",
    "\n",
    "# Load later using:\n",
    "# model = joblib.load('nids_rf_model.pkl')\n",
    "# preprocessor = joblib.load('nids_preprocessor.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Enhanced Preprocessing ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load your dataset here\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Handling missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Removing outliers using IQR\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Splitting features and labels\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448cd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Model Pipeline and Training ===\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Classifier pipeline\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', CalibratedClassifierCV(RandomForestClassifier(n_estimators=100), method='sigmoid'))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(clf_pipeline, 'nids_model_pipeline.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3623cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Postprocessing and Evaluation ===\n",
    "# Predict probabilities and threshold\n",
    "y_proba = clf_pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_proba > 0.7).astype(int)  # Use thresholding\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"False Positives:\", cm[0][1])\n",
    "print(\"False Negatives:\", cm[1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Explainability with SHAP ===\n",
    "import shap\n",
    "\n",
    "# Use a sample for SHAP due to performance\n",
    "X_sample = X_test[:100]\n",
    "\n",
    "# Explain model predictions\n",
    "explainer = shap.Explainer(clf_pipeline.named_steps['classifier'].base_estimator)\n",
    "shap_values = explainer(clf_pipeline.named_steps['preprocessor'].transform(X_sample))\n",
    "\n",
    "# Visualize\n",
    "shap.plots.beeswarm(shap_values)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
